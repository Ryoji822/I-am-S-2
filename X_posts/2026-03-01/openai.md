# OpenAI X投稿 - 2026-03-01

収集元: ローカルRSSHub (localhost:1200)

---

## @sama (Sam Altman - CEO)

**05:38 JST** | [原文](https://x.com/sama/status/2027850288959525125)

> RT OpenAI
> Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI deployments, including Anthropic's. Here's why: https://openai.com/index/our-agreement-with-the-department-of-war/

---

## @jasonkwon (Jason Kwon - 戦略担当)

**05:38 JST** | [原文](https://x.com/jasonkwon/status/2027855528253395261)

> RT OpenAI
> Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI deployments, including Anthropic's. Here's why: https://openai.com/index/our-agreement-with-the-department-of-war/

---

**05:38 JST** | [原文](https://x.com/jasonkwon/status/2027855589381132293)

> RT Boaz Barak
> Please read this blog post. Our red lines are clear and we will protect them. Unlike other agreements, we are not working through Palantir, we are responsible for our own models and our own safety. We will have our people in place to guarantee that responsible & safe deployment.
> 
> Boaz Barak: https://openai.com/index/our-agreement-with-the-department-of-war/

---

## @polynoamial (Noam Brown - 研究者)

**05:55 JST** | [原文](https://x.com/polynoamial/status/2027850059875029335)

> For those following the DoW AI drama, I highly recommend reading this post explaining how @OpenAI approached the negotiations with the DoW.
> 
> OpenAI: Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI

---

## @jasonkwon (Jason Kwon - 戦略担当)

**08:14 JST** | [原文](https://x.com/jasonkwon/status/2027892779796594860)

> RT Tibo
> Personal view. On the DoW deal, time and time again I witness how OpenAI operates thoughtfully and diplomatically when it comes to raising the bar on safety. I also believe that figuring out how to deploy powerful new technology in the pursuit of national security (not just the USA) is important.
> 
> The company deeply understands what it can and cannot reasonably have control over and focuses instead of setting the right guardrails to ensure that deployment is aligned with what is considered acceptable and safe.
> 
> I am proud of the level of transparency provided in the blog post, and hope that other companies, including Anthropic, were as transparent on prior and future deals they make.
> 
> https://openai.com/index/our-agreement-with-the-department-of-war/

---

## @jasonkwon (Jason Kwon - 戦略担当)

**09:05 JST** | [原文](https://x.com/jasonkwon/status/2027901571930157153)

> RT Dean W. Ball
> When it comes to all these contract terms and disputes about them:
> 
> I really don’t know. There may be a deal to be had there, and I put a high value on putting an end to this madness. But to know whether the deal is worth taking would require serious conversations with highly specialized lawyers, and essentially no one commenting on these issues has really done that (Alan rozenshtein exempted). I am not one of those lawyers, and this is not an area of the law I’ve spent a long time dabbling in (unlike say first amendment jurisprudence, where I’d be much more inclined to weigh in on legal matters despite not being a lawyer).
> 
> But in the end I feel this is all a distraction. The question here is pretty simple: should the United States government be able to use policy to destroy a law-abiding American company because it feels like it? My answer is no, and yours should be too. The rest is noise.

---

