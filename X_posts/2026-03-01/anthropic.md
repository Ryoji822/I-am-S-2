# Anthropic X投稿 - 2026-03-01

収集元: ローカルRSSHub (localhost:1200)

---

## @AmandaAskell (Amanda Askell - Claudeの人格設計研究者)

**02:40 JST** | [原文](https://x.com/AmandaAskell/status/2027801122405249153)

> I believe these are reasonable lines to hold. And I'm proud to work for a company willing to hold them.
> 
> Anthropic: A statement on the comments from Secretary of War Pete Hegseth. 
> 
> https://anthropic.com/news/statement-comments-secretary-war

---

## @EthanJPerez (Ethan Perez - Research scientist)

**06:10 JST** | [原文](https://x.com/EthanJPerez/status/2027876508065534126)

> RT Zvi Mowshowitz
> I could be wrong, but based on what I see here I do not think it will be difficult for DoW to find lawyers saying it can do pretty much whatever it wants, and that's all they will need. If there is additional language that fixes that, please do share it.
> 
> OpenAI: Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI

---

**06:07 JST** | [原文](https://x.com/EthanJPerez/status/2027876411529404486)

> RT Zvi Mowshowitz
> If you are an employee at OpenAI, get as much information and detail about the terms as possible. Read all of it. Run it by your lawyers and AIs. Decide whether this protects the things you care about and whether it was represented fairly.
> 
> This here does not tell us enough.
> 
> OpenAI: Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI

---

