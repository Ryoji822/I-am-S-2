# Anthropic X投稿 - 2026-03-01

収集元: ローカルRSSHub (localhost:1200)

---

## @AmandaAskell (Amanda Askell - Claudeの人格設計研究者)

**02:40 JST** | [原文](https://x.com/AmandaAskell/status/2027801122405249153)

> I believe these are reasonable lines to hold. And I'm proud to work for a company willing to hold them.
> 
> Anthropic: A statement on the comments from Secretary of War Pete Hegseth. 
> 
> https://anthropic.com/news/statement-comments-secretary-war

---

## @EthanJPerez (Ethan Perez - Research scientist)

**06:10 JST** | [原文](https://x.com/EthanJPerez/status/2027876508065534126)

> RT Zvi Mowshowitz
> I could be wrong, but based on what I see here I do not think it will be difficult for DoW to find lawyers saying it can do pretty much whatever it wants, and that's all they will need. If there is additional language that fixes that, please do share it.
> 
> OpenAI: Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI

---

**06:07 JST** | [原文](https://x.com/EthanJPerez/status/2027876411529404486)

> RT Zvi Mowshowitz
> If you are an employee at OpenAI, get as much information and detail about the terms as possible. Read all of it. Run it by your lawyers and AIs. Decide whether this protects the things you care about and whether it was represented fairly.
> 
> This here does not tell us enough.
> 
> OpenAI: Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI

---

## @EthanJPerez (Ethan Perez - Research scientist)

**04:21 JST** | [原文](https://x.com/EthanJPerez/status/2027878295401038294)

> RT jeremy
> Re Even if it were the case that OAI’s contract with the DoW was much safer and had the key limitations (it’s not and it doesn’t), OAI shouldn’t have defected and taken the deal. Doing so undermines the solidarity of AI labs and encourages further overreaches.

---

**00:32 JST** | [原文](https://x.com/EthanJPerez/status/2027878994847367269)

> RT Miles Brundage
> In light of what external lawyers and the Pentagon are saying, OpenAI employees’ default assumption here should unfortunately be that OpenAI caved + framed it as not caving, and screwed Anthropic while framing it as helping them.
> 
> Hope that is wrong + they get evidence otherwise

---

