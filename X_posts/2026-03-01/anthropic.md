# Anthropic X投稿 - 2026-03-01

収集元: ローカルRSSHub (localhost:1200)

---

## @AmandaAskell (Amanda Askell - Claudeの人格設計研究者)

**02:40 JST** | [原文](https://x.com/AmandaAskell/status/2027801122405249153)

> I believe these are reasonable lines to hold. And I'm proud to work for a company willing to hold them.
> 
> Anthropic: A statement on the comments from Secretary of War Pete Hegseth. 
> 
> https://anthropic.com/news/statement-comments-secretary-war

---

## @EthanJPerez (Ethan Perez - Research scientist)

**06:10 JST** | [原文](https://x.com/EthanJPerez/status/2027876508065534126)

> RT Zvi Mowshowitz
> I could be wrong, but based on what I see here I do not think it will be difficult for DoW to find lawyers saying it can do pretty much whatever it wants, and that's all they will need. If there is additional language that fixes that, please do share it.
> 
> OpenAI: Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI

---

**06:07 JST** | [原文](https://x.com/EthanJPerez/status/2027876411529404486)

> RT Zvi Mowshowitz
> If you are an employee at OpenAI, get as much information and detail about the terms as possible. Read all of it. Run it by your lawyers and AIs. Decide whether this protects the things you care about and whether it was represented fairly.
> 
> This here does not tell us enough.
> 
> OpenAI: Yesterday we reached an agreement with the Department of War for deploying advanced AI systems in classified environments, which we requested they make available to all AI companies.
> 
> We think our deployment has more guardrails than any previous agreement for classified AI

---

## @EthanJPerez (Ethan Perez - Research scientist)

**04:21 JST** | [原文](https://x.com/EthanJPerez/status/2027878295401038294)

> RT jeremy
> Re Even if it were the case that OAI’s contract with the DoW was much safer and had the key limitations (it’s not and it doesn’t), OAI shouldn’t have defected and taken the deal. Doing so undermines the solidarity of AI labs and encourages further overreaches.

---

**00:32 JST** | [原文](https://x.com/EthanJPerez/status/2027878994847367269)

> RT Miles Brundage
> In light of what external lawyers and the Pentagon are saying, OpenAI employees’ default assumption here should unfortunately be that OpenAI caved + framed it as not caving, and screwed Anthropic while framing it as helping them.
> 
> Hope that is wrong + they get evidence otherwise

---

## @EthanJPerez (Ethan Perez - Research scientist)

**07:40 JST** | [原文](https://x.com/EthanJPerez/status/2027897201595404394)

> RT Nate Silver
> The eagerness for OpenAI to sign the contract on the very night their rival got fired is likely to be a lot more revealing than the contract terms, which in any event are ambiguous and unlikely to be enforced by a court that gives a lot of deference to the executive.

---

**02:33 JST** | [原文](https://x.com/EthanJPerez/status/2027897581968437650)

> RT Ben Springwater
> Sam Altman posted three identical copies of his announcement to dilute the reactions.
> 
> As of now, they have 18M, 8.8M, and 5.9M views respectively.

---

**00:27 JST** | [原文](https://x.com/EthanJPerez/status/2027897518156316880)

> RT Nate Silver
> One also wonders how much talent OpenAI might lose from all of this and if talent is underrated relative to capital. Anthropic had already been catching up valuation wise and Claude was increasingly considered the #1 LLM by influential users.

---

## @EthanJPerez (Ethan Perez - Research scientist)

**06:29 JST** | [原文](https://x.com/EthanJPerez/status/2027920689450319918)

> RT Lawrence Chan
> Re Now, I'm sure OpenAI will claim that the real teeth of the agreement is not their contract but their deployment architecture: they have a "safety stack that includes these principles" and everything! (In other words, "trust me, bro.")

---

**06:26 JST** | [原文](https://x.com/EthanJPerez/status/2027920659222040652)

> RT Lawrence Chan
> Re They also make the claim that because their model lives on their cloud and isn't "edge deployment", that this by definition would not count as "fully autonomous weapons". Maybe this is _technically true_ in that the weapon needs to communicate with their server, but it does not guarantee human-in-the-loop, and does not mean that their model will not make kill decisions on behalf of drones or missiles linked to it.

---

**06:23 JST** | [原文](https://x.com/EthanJPerez/status/2027920576116101178)

> RT Lawrence Chan
> Re This, of course, did not stop OpenAI from blatantly misrepresenting this language in the blog post and in Sam Altman's tweets!

---

**06:18 JST** | [原文](https://x.com/EthanJPerez/status/2027920536857411810)

> RT Lawrence Chan
> OpenAI has released the language in their contract with the DoW, and it's exactly as Anthropic was claiming: "legalese that would allow those safeguards to be disregarded at will". 
> 
> Note: the first paragraph doesn't say "no autonomous weapons"! It says "AI can't control autonomous weapons as long as existing law (that doesn't exist) or the DoD says so."
> 
> Similarly, the mass surveillance use cases will "comply with existing law", but many forms of data collection that we'd consider "mass surveillance" are things that the NSA has consistently argued are legal under current law.

---

## @EthanJPerez (Ethan Perez - Research scientist)

**19:04 JST** | [原文](https://x.com/EthanJPerez/status/2028221017165103330)

> RT Leo Gao
> the contract snippet from the openai dow blog post is so obviously just "all lawful use" followed by a bunch of stuff that is not really operative except as window dressing.
> the referenced DoD Directive 3000.09 basically says the DoD gets to decide when autonomous weapons systems are deployable.
> as others have covered, there are a ton of mass domestic surveillance loopholes not covered by the 4A, national security act, FISA, etc.

---

