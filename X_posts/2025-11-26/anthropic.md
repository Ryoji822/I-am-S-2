# Anthropic X投稿 - 2025-11-26

収集元: ローカルRSSHub (localhost:1200)

---

## @janleike (Jan Leike - Alignment Scienceリーダー)

**03:48 JST** | [原文](https://x.com/janleike/status/1993412369062724022)

> RT rowan
> New Anthropic research: We build a diverse suite of dishonest models and use it to systematically test methods for improving honesty and detecting lies.
> 
> Of the 25+ methods we tested, simple ones, like fine-tuning models to be honest despite deceptive instructions, worked best.

---

