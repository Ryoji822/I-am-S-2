# OpenAI XæŠ•ç¨¿ - 2026-02-15

åŽé›†å…ƒ: ãƒ­ãƒ¼ã‚«ãƒ«RSSHub (localhost:1200)

---

## @OpenAIDevs (OpenAI Developers - å…¬å¼é–‹ç™ºè€…ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ)

**05:03 JST** | [åŽŸæ–‡](https://x.com/OpenAIDevs/status/2022763675233456205)

> http://x.com/i/article/2022760628889489414

---

## @gdb (Greg Brockman - å…±åŒå‰µæ¥­è€…)

**09:02 JST** | [åŽŸæ–‡](https://x.com/gdb/status/2022823856889827711)

> codex's shell-fu is incredible to behold and learn from

---

**07:45 JST** | [åŽŸæ–‡](https://x.com/gdb/status/2022804437308445042)

> GPT-5.3-Codex for UI design:
> 
> TK Kong:â€‚Wow gpt 5.3 Codex is actually so good. It has significantly better taste for UI design.
> 
> My bet is that it'll be #1 on @designarena once API is available.

---

**06:39 JST** | [åŽŸæ–‡](https://x.com/gdb/status/2022787705852268799)

> with codex, feels like whatever can be imagined can be created

---

**04:28 JST** | [åŽŸæ–‡](https://x.com/gdb/status/2022754798915981356)

> AI for science and mathematics is an emerging area with potential to uplift quality of life for every human (and animal!)
> 
> Bartosz NaskrÄ™cki:â€‚@sama I am very glad you got engaged deep into this experiment. Mathematical community needs strong signal from the AI labs that science is a serious engagement for you. Mathematics in its full proof-driven form is a pinnacle of human ingenuity and knowing how well the models can grasp

---

## @kevinweil (Kevin Weil - è£½å“è²¬ä»»è€…)

**02:46 JST** | [åŽŸæ–‡](https://x.com/kevinweil/status/2022776858056757592)

> RTâ€‚Sam Altman
> We went from AI systems that struggled to do grade school math to AI systems that can solve research-level math problems in just a few years.
> 
> I agree with Jakub this is perhaps the most important eval now.
> 
> I am also pretty sure the main reaction will be "it's not that hard" :)
> 
> Jakub Pachocki:â€‚Very excited about the "First Proof" challenge. I believe novel frontier research is perhaps the most important way to evaluate capabilities of the next generation of AI models.
> 
> We have run our internal model with limited human supervision on the ten proposed problems. The

---

## @npew (Peter Welinder - ç ”ç©¶ãƒ»æŠ€è¡“)

**14:50 JST** | [åŽŸæ–‡](https://x.com/npew/status/2023109176092987610)

> RTâ€‚Austen Allred
> In the next 6 months a lot of them will switch to Codex
> 
> Andy Li:â€‚Almost every YC founder Iâ€™ve talked to switched from Cursor to Claude Code.
> 
> Am I the only one still on Cursor?

---

**13:50 JST** | [åŽŸæ–‡](https://x.com/npew/status/2023109703174369741)

> RTâ€‚Morgan
> If you haven't tried this prompt with GPT 5.3 Codex yet, try it, then go to sleep and let it cook.
> 
> Currently doing a build it's estimating will take it 8-14 hours.
> 
> Goodnight.

---

## @polynoamial (Noam Brown - ç ”ç©¶è€…)

**08:39 JST** | [åŽŸæ–‡](https://x.com/polynoamial/status/2022818095879065610)

> Perhaps a ðŸŒ¶ï¸ take but I think the criticisms of @GoogleDeepMind's release are missing the point, and the real problem is that AI labs and safety orgs need to adapt to a world where intelligence is a function of inference compute.
> 
> When Google says that Deep Think poses no new risks beyond Gemini 3 Pro, they probably mean that Deep Think is a scaffold of Gemini 3 Pro that anyone externally could have constructed on their own anyway. In other words, the capabilities of Deep Think have always been available to anyone willing to pay for Deep Think amounts of inference, simply by scaffolding a bunch of Gemini 3 Pro queries together. Deep Think just makes that more convenient for the casual user.
> 
> The corollary of this is that capabilities far beyond Gemini 3 Deep Think are already available to anyone willing to scaffold a system together that uses even more inference compute. As a trivial example, you could run 10 Deep Think queries and just do consensus over them. That would be 10x the cost but would have higher performance on many benchmarks.
> 
> Most Preparedness Frameworks were developed in ~2023 before the era of effective test-time scaling. But today, there is a massive difference on the hardest evals between something like GPT-5.2 Low and GPT-5.2 Extra High. Scaffolds are also much more effective. So if you want to evaluate whether Gemini 3 can, for example, help make a bio weapon, the answer may depend on how much inference compute you give it.
> 
> In my opinion, the proper solu...(truncated)

---

