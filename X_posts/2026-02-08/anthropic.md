# Anthropic X投稿 - 2026-02-08

収集元: ローカルRSSHub (localhost:1200)

---

## @jackclarkSF (Jack Clark - 共同創業者 / Policy)

**03:45 JST** | [原文](https://x.com/jackclarkSF/status/2020208143876387244)

> RT Claude
> Our teams have been building with a 2.5x-faster version of Claude Opus 4.6.
> 
> We’re now making it available as an early experiment via Claude Code and our API.

---

## @sleepinyourhat (Sam Bowman - 技術安全性)

**03:24 JST** | [原文](https://x.com/sleepinyourhat/status/2020205489062314464)

> RT Dean W. Ball
> Fascinating. This might be the first example of someone trying to take genuine "frontier AI governance" issues and make them political. It should be no surprise to see such things in the Democratic primary for San Francisco's House seat. This person is running against Scott Wiener, attempting to carve out space "to the left" of Wiener on AI safety. 
> 
> First and foremost this is just interesting, a new evolution in the politics of AI. A few other thoughts:
> 
> 1. The claim/question Chakrabarti raises seems legitimate to an unengaged user. But a professional who follows this topic will have read the Opus 4.6 system card by now and have noted, among its 200 plus pages of rigorous evaluation results, numerous examples of positive alignment findings. This snippet is not indicative of the overall Opus 4.6 system card. Even Apollo's finding, in the end, is rather tepid--"no evidence for or against."
> 
> 2. The Apollo finding is one of the only negative of several third-party evaluations conducted on the model and reported in the system card. That Anthropic would even publish the negative findings of another organization (findings that contradict their own work) in a public company document about a new product is itself extraordinary! Generally this sort of thing doesn't happen in market capitalism, yet it is relatively common to see in frontier AI system cards. 
> 
> 3. Politicians beating up on Anthropic for having a few negative, screenshot-able paragraphs in a 200+ page repo...(truncated)

---

