# OpenAI X投稿 - 2026-02-08

収集元: ローカルRSSHub (localhost:1200)

---

## @jasonkwon (Jason Kwon - 戦略担当)

**12:30 JST** | [原文](https://x.com/jasonkwon/status/2020670268922839537)

> RT Dean W. Ball
> If you believe that AI means social capital becomes more important, then spending all day in group chats/Twitter tabs with the occasional command-tab over to Terminal to press 'enter' is not necessarily decadent but perhaps even economically rational.

---

**06:46 JST** | [原文](https://x.com/jasonkwon/status/2020275310194024848)

> RT Garry Tan
> Boil the Oceans
> 
> You know the phrase: “don’t boil the ocean.” Everyone’s said it in some overly ambitious meeting. It’s good advice in normal times. It keeps teams focused. It prevents scope creep. But we are no longer in normal times, and I think it’s time to retire saying it.
> 
> Artificial Superintelligence means it’s time to boil the ocean. We’ll start with a few lakes first.
> 
> I was recently with a university endowment’s head of private investing who told me their engineers were terrified for their jobs after seeing what Claude Code could do. And I get it — that’s the natural first reaction. But it’s the wrong one. It’s a zero-sum reaction to a positive-sum moment.
> 
> Instead of worrying about doing the same thing we’ve been doing for cheaper, why not focus on doing the thing we never even dreamed of doing? Why can’t that endowment achieve 50% net IRR instead of 10%? Why can’t a startup deliver a service that is 100x better than the incumbent? Why can’t we have fusion energy? Why can’t we talk to every single user and have a perfect understanding of every bug in our product?
> 
> These aren’t rhetorical questions anymore. They’re engineering problems with paths to solutions.
> 
> Here is what I think is actually going on with the fear: our fear of the future is directly proportional to how small our ambitions are. If your plan is to keep doing exactly what you’re doing, then yes, a machine that can do it faster and cheaper is terrifying. But if your plan is to do somethin...(truncated)

---

## @polynoamial (Noam Brown - 研究者)

**07:16 JST** | [原文](https://x.com/polynoamial/status/2020262825525231895)

> RT Dean W. Ball
> The use of GPT-5 as evidence that "AI is slowing down" is a legendary example of mass delusion. Yes, its release timing gave that impression (I will rehash it below for those interested) to uninformed observers, but anyone paying attention should have known. I'll repeat it: it should have been *obvious* to anyone paying even slight attention to frontier AI that GPT-5 was not evidence of a slowdown in AI. 
> 
> Why? Rehash: OpenAI forked its model releases in September 2024 with the reasoning models; from the release of o1-preview in September 2024 to the release of GPT-5 in July 2025, the most interesting and capable OpenAI models were not generally within the GPT family but instead the o family.
> 
> In particular, OpenAI o3 was a breakthrough moment, a model that inspired me, a few days after its release, to announce my departure from my think tank job to the White House, "Take Off." o3 legitimately feels classic now, quaint almost, but it still feels insane to think about the year-on-year progress: GPT-4 Turbo in April 2024 to OpenAI o3 in April 2025 was in and of itself astounding. 
> 
> For months (starting, if memory serves, in Fall 2024), OpenAI staff and leadership had spoken explicitly of the need to unify the "o" reasoning models and the consumer-friendly GPT line. GPT-5 was that attempt. Thus it is closer to correct to think of GPT-5 as "o3 + a GPT-4.1ish model" than it is a true next-generation model. 
> 
> The naming convention was deeply confusing, and this was ...(truncated)

---

**05:42 JST** | [原文](https://x.com/polynoamial/status/2020236875496321526)

> When GPT-5 was released, some folks claimed AI progress was hitting a wall, whereas others said progress would continue.
> 
> GPT-5.2 was released 2 months ago. GPT-5.3-Codex was released 2 days ago and is twice as token efficient for coding. It's clear who turned out to be correct.

---

