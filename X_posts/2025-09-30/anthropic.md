# Anthropic XæŠ•ç¨¿ - 2025-09-30

åŽé›†å…ƒ: ãƒ­ãƒ¼ã‚«ãƒ«RSSHub (localhost:1200)

---

## @janleike (Jan Leike - Alignment Scienceãƒªãƒ¼ãƒ€ãƒ¼)

**02:47 JST** | [åŽŸæ–‡](https://x.com/janleike/status/1972771577310957759)

> RTâ€‚Sam Bowman
> [Sonnet 4.5 ðŸ§µ] Here's the north-star goal for our pre-deployment alignment evals work:
> 
> The information we share alongside a model should give you an accurate overall sense of the risks the model could pose. It wonâ€™t tell you everything, but you shouldnâ€™t be...

---

