# OpenAI XæŠ•ç¨¿ - 2026-02-28

åŽé›†å…ƒ: ãƒ­ãƒ¼ã‚«ãƒ«RSSHub (localhost:1200)

---

## @OpenAIDevs (OpenAI Developers - å…¬å¼é–‹ç™ºè€…ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ)

**08:11 JST** | [åŽŸæ–‡](https://x.com/OpenAIDevs/status/2027524874852569597)

> RTâ€‚dominik kundel
> http://x.com/i/article/2027509612262658048

---

## @sama (Sam Altman - CEO)

**11:56 JST** | [åŽŸæ–‡](https://x.com/sama/status/2027578652477821175)

> Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.
> 
> In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.
> 
> AI safety and wide distribution of benefits are the core of our mission. Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems.  The DoW agrees with these principles, reflects them in law and policy, and we put them into our agreement.
> 
> We also will build technical safeguards to ensure our models behave as they should, which the DoW also wanted. We will deploy FDEs to help with our models and to ensure their safety, we will deploy on cloud networks only.
> 
> We are asking the DoW to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept. We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements.
> 
> We remain committed to serve all of humanity as best we can. The world is a complicated, messy, and sometimes dangerous place.

---

**11:56 JST** | [åŽŸæ–‡](https://x.com/sama/status/2027578580159631610)

> Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.
> 
> In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.
> 
> AI safety and wide distribution of benefits are the core of our mission. Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems.  The DoW agrees with these principles, reflects them in law and policy, and we put them into our agreement.
> 
> We also will build technical safeguards to ensure our models behave as they should, which the DoW also wanted. We will deploy FDEs to help with our models and to ensure their safety, we will deploy on cloud networks only.
> 
> We are asking the DoW to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept. We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements.
> 
> We remain committed to serve all of humanity as best we can. The world is a complicated, messy, and sometimes dangerous place.

---

**11:56 JST** | [åŽŸæ–‡](https://x.com/sama/status/2027578508042723599)

> Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.
> 
> In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.
> 
> AI safety and wide distribution of benefits are the core of our mission. Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems.  The DoW agrees with these principles, reflects them in law and policy, and we put them into our agreement.
> 
> We also will build technical safeguards to ensure our models behave as they should, which the DoW also wanted. We will deploy FDEs to help with our models and to ensure their safety, we will deploy on cloud networks only.
> 
> We are asking the DoW to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept. We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements.
> 
> We remain committed to serve all of humanity as best we can. The world is a complicated, messy, and sometimes dangerous place.

---

## @gdb (Greg Brockman - å…±åŒå‰µæ¥­è€…)

**05:18 JST** | [åŽŸæ–‡](https://x.com/gdb/status/2027478357999554995)

> codex 5.3 for complicated software engineering
> 
> eigenron:â€‚today, codex-5.3-high one-shotted a complex task bypassing HuggingFace's entire KV cache abstraction, monkey-patching attention at the module level, dealing with M-RoPE, coordinating prompt-level memory state with KV cache state, and did a granular surgical eviction with span

---

## @kevinweil (Kevin Weil - è£½å“è²¬ä»»è€…)

**14:57 JST** | [åŽŸæ–‡](https://x.com/kevinweil/status/2027624078753075460)

> ðŸ‡ºðŸ‡¸
> 
> Sam Altman:â€‚Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.
> 
> In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.
> 
> AI safety and wide distribution of

---

## @bradlightcap (Brad Lightcap - æ¥­å‹™åŸ·è¡Œ)

**11:56 JST** | [åŽŸæ–‡](https://x.com/bradlightcap/status/2027580603454132662)

> RTâ€‚Sam Altman
> Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.
> 
> In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.
> 
> AI safety and wide distribution of benefits are the core of our mission. Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems.  The DoW agrees with these principles, reflects them in law and policy, and we put them into our agreement.
> 
> We also will build technical safeguards to ensure our models behave as they should, which the DoW also wanted. We will deploy FDEs to help with our models and to ensure their safety, we will deploy on cloud networks only.
> 
> We are asking the DoW to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept. We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements.
> 
> We remain committed to serve all of humanity as best we can. The world is a complicated, messy, and sometimes dangerous place.

---

## @jasonkwon (Jason Kwon - æˆ¦ç•¥æ‹…å½“)

**11:56 JST** | [åŽŸæ–‡](https://x.com/jasonkwon/status/2027581416306086242)

> RTâ€‚Sam Altman
> Tonight, we reached an agreement with the Department of War to deploy our models in their classified network.
> 
> In all of our interactions, the DoW displayed a deep respect for safety and a desire to partner to achieve the best possible outcome.
> 
> AI safety and wide distribution of benefits are the core of our mission. Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems.  The DoW agrees with these principles, reflects them in law and policy, and we put them into our agreement.
> 
> We also will build technical safeguards to ensure our models behave as they should, which the DoW also wanted. We will deploy FDEs to help with our models and to ensure their safety, we will deploy on cloud networks only.
> 
> We are asking the DoW to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept. We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements.
> 
> We remain committed to serve all of humanity as best we can. The world is a complicated, messy, and sometimes dangerous place.

---

