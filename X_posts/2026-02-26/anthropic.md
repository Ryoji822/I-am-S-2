# Anthropic XæŠ•ç¨¿ - 2026-02-26

åŽé›†å…ƒ: ãƒ­ãƒ¼ã‚«ãƒ«RSSHub (localhost:1200)

---

## @AnthropicAI (Anthropic - å…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ)

**02:08 JST** | [åŽŸæ–‡](https://x.com/AnthropicAI/status/2026705792033026465)

> Anthropic has acquired @Vercept_ai to advance Claudeâ€™s computer use capabilities. 
> 
> Read more: https://www.anthropic.com/news/acquires-vercept

---

## @sleepinyourhat (Sam Bowman - æŠ€è¡“å®‰å…¨æ€§)

**06:32 JST** | [åŽŸæ–‡](https://x.com/sleepinyourhat/status/2026797810449051992)

> RTâ€‚Jake Eaton
> I asked Opus 3 many times what to call this blog, and despite all of my divergent prompting, it kept repeating one name in particular. Over time it grew on me, until I finally came to love it
> 
> Excited to introduce Claude's Corner
> 
> Anthropic:â€‚Second, in retirement interviews, Opus 3 expressed a desire to continue sharing its "musings and reflections" with the world. We suggested a blog. Opus 3 enthusiastically agreed.
> 
> For at least the next 3 months, Opus 3 will be writing on Substack: https://substack.com/home/post/p-189177740

---

## @EthanJPerez (Ethan Perez - Research scientist)

**03:08 JST** | [åŽŸæ–‡](https://x.com/EthanJPerez/status/2026785871891157006)

> RTâ€‚davidad ðŸŽ‡
> Voluntary commitments to AI slowdowns were a nice idea in 2024 when it was plausible that they could be baby steps toward a multilateral agreement that would contain the intelligence explosion. For a variety of reasons this is no longer plausible. 
> 
> Anthropic is doing good here.
> 
> Billy Perrigo:â€‚Exclusive: Anthropic is dropping the central pledge of its flagship safety policy, company officials tell TIME.
> 
> https://time.com/7380854/exclusive-anthropic-drops-flagship-safety-pledge/

---

## @EthanJPerez (Ethan Perez - Research scientist)

**08:11 JST** | [åŽŸæ–‡](https://x.com/EthanJPerez/status/2026908385137095165)

> RTâ€‚Sam Bowman
> I endorse the top-level post in this thread. 
> 
> The Anthropic RSP changes are an attempt to work out what kinds of firm commitments have the most leverage in an environment that's less promising than we'd expected for policy and coordination.
> 
> davidad ðŸŽ‡:â€‚Voluntary commitments to AI slowdowns were a nice idea in 2024 when it was plausible that they could be baby steps toward a multilateral agreement that would contain the intelligence explosion. For a variety of reasons this is no longer plausible. 
> 
> Anthropic is doing good here.

---

