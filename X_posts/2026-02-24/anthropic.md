# Anthropic X投稿 - 2026-02-24

収集元: ローカルRSSHub (localhost:1200)

---

## @AnthropicAI (Anthropic - 公式アカウント)

**00:06 JST** | [原文](https://x.com/AnthropicAI/status/2025950279099961854)

> New research: The AI Fluency Index.
> 
> We tracked 11 behaviors across thousands of http://Claude.ai conversations—for example, how often people iterate and refine their work with Claude—to measure how well people collaborate with AI.
> 
> Read more: https://www.anthropic.com/research/AI-fluency-index

---

## @sleepinyourhat (Sam Bowman - 技術安全性)

**07:43 JST** | [原文](https://x.com/sleepinyourhat/status/2026075018137079977)

> RT Chris Olah
> I'm increasingly taking pretty strong versions of this view seriously.
> 
> Anthropic: AI assistants like Claude can seem shockingly human—expressing joy or distress, and using anthropomorphic language to describe themselves. Why?
> 
> In a new post we describe a theory that explains why AIs act like humans: the persona selection model.
> 
> https://www.anthropic.com/research/persona-selection-model

---

## @EthanJPerez (Ethan Perez - Research scientist)

**03:15 JST** | [原文](https://x.com/EthanJPerez/status/2026050810191495677)

> RT Anthropic
> We’ve identified industrial-scale distillation attacks on our models by DeepSeek, Moonshot AI, and MiniMax.
> 
> These labs created over 24,000 fraudulent accounts and generated over 16 million exchanges with Claude, extracting its capabilities to train and improve their own models.

---

## @AnthropicAI (Anthropic - 公式アカウント)

**09:45 JST** | [原文](https://x.com/AnthropicAI/status/2026096054253564002)

> We're proud to support @LACMA's Art + Technology Lab—a program that empowers artists to prototype ideas at the edges of art, science, and emerging technology.
> 
> The 2026 call for proposals is open to artists worldwide. Grants up to $50K.
> 
> Apply by Apr 22: http://lacma.org/art/lab/grants

---

## @AmandaAskell (Amanda Askell - Claudeの人格設計研究者)

**05:16 JST** | [原文](https://x.com/AmandaAskell/status/2026422460850254279)

> RT Joe Carlsmith
> .@AmandaAskell and I are recording an audio version of Claude’s Constitution, and we’re planning to include an additional section where we answer some questions about the document. If you have questions you’re especially curious about, feel free to drop them in the replies.

---

## @AmandaAskell (Amanda Askell - Claudeの人格設計研究者)

**07:43 JST** | [原文](https://x.com/AmandaAskell/status/2026706321236795600)

> RT Chris Olah
> I'm increasingly taking pretty strong versions of this view seriously.
> 
> Anthropic: AI assistants like Claude can seem shockingly human—expressing joy or distress, and using anthropomorphic language to describe themselves. Why?
> 
> In a new post we describe a theory that explains why AIs act like humans: the persona selection model.
> 
> https://www.anthropic.com/research/persona-selection-model

---

