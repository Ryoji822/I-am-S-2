# Anthropic X投稿 - 2026-02-24

収集元: ローカルRSSHub (localhost:1200)

---

## @AnthropicAI (Anthropic - 公式アカウント)

**00:06 JST** | [原文](https://x.com/AnthropicAI/status/2025950279099961854)

> New research: The AI Fluency Index.
> 
> We tracked 11 behaviors across thousands of http://Claude.ai conversations—for example, how often people iterate and refine their work with Claude—to measure how well people collaborate with AI.
> 
> Read more: https://www.anthropic.com/research/AI-fluency-index

---

## @sleepinyourhat (Sam Bowman - 技術安全性)

**07:43 JST** | [原文](https://x.com/sleepinyourhat/status/2026075018137079977)

> RT Chris Olah
> I'm increasingly taking pretty strong versions of this view seriously.
> 
> Anthropic: AI assistants like Claude can seem shockingly human—expressing joy or distress, and using anthropomorphic language to describe themselves. Why?
> 
> In a new post we describe a theory that explains why AIs act like humans: the persona selection model.
> 
> https://www.anthropic.com/research/persona-selection-model

---

## @EthanJPerez (Ethan Perez - Research scientist)

**03:15 JST** | [原文](https://x.com/EthanJPerez/status/2026050810191495677)

> RT Anthropic
> We’ve identified industrial-scale distillation attacks on our models by DeepSeek, Moonshot AI, and MiniMax.
> 
> These labs created over 24,000 fraudulent accounts and generated over 16 million exchanges with Claude, extracting its capabilities to train and improve their own models.

---

## @AnthropicAI (Anthropic - 公式アカウント)

**09:45 JST** | [原文](https://x.com/AnthropicAI/status/2026096054253564002)

> We're proud to support @LACMA's Art + Technology Lab—a program that empowers artists to prototype ideas at the edges of art, science, and emerging technology.
> 
> The 2026 call for proposals is open to artists worldwide. Grants up to $50K.
> 
> Apply by Apr 22: http://lacma.org/art/lab/grants

---

